# The Tale of T0

> We trained a language model capable of generalizing to unseen natural language tasks while outperforming (or matching) extremely large language models despite being 16x smaller. This is important because a lot of language tasks do not have readily available labels for training. In this blog, we showcase its applications in cooking and answering world knowledge questions.


### **Overview**
When large language models such as GPT-3 (Brown et al., 2020) succeeded in performing downstream tasks without ever finetuning on these tasks, the NLP community got excited about the future of zero-shot (and few-shot) learning: pretrained language models can potentially be applied to a variety of tasks without any (or very few) labeled data and get non-trivial performance.

<p align="center">
<img src="uploads/images/T0.png" alt="T0" width="500"/> 
</p>


At BigScience, we explored the following research question: ‚Äú**if we explicitly train a language model on a massive mixture of diverse NLP tasks, would it generalize to unseen NLP tasks?**‚Äù And the answer is yes (to a certain extent)! We named the resulting model *T0* as *T5 (Raffel et al., 2020) for zero-shot*. T0 is trained on a diverse mixture of tasks such as summarization and question answering, and performs well on unseen tasks such as natural language inference.

A natural strategy to train a model on a massive multi-task mixture is to use *natural language prompting*. The key is to reformulate any NLP task into a text-to-text format as if we are asking another person for the answer to the task. The *prompt* is the part that asks a query about a given instance. With prompting, the model simply receives the text prompt as input and returns a text output.

<p align="center">
<img src="uploads/images/natural-language-prompting.png" alt="T0" width="800"/> 
</p>

To create T0, we first collect and convert NLP datasets into a text-to-text format (through crowdsourcing efforts and the [promptsource](https://github.com/bigscience-workshop/promptsource) tool). To achieve this goal, we have collected around 2‚Äô000 prompts for 170 English datasets. Next, we fine-tune a version of the pretrained T5 language model on the massive mixture of NLP tasks.

T0 is trained on a diverse set of tasks and prompts. This leads to increased robustness to the prompt wording. Users can structure prompts in an interrogative or affirmative fashion, put instructions at the start or the end of the prompt, or format answer choices as part of a grammatical question or as a list; as long as the input prompt reads naturally, T0 can produce a meaningful response.

### **Capabilities**

T0 outperforms or matches extremely large language models 16x larger in size, which have 100s of billions of parameters, on a variety of unseen tasks. T0 not only generalizes well to NLP tasks (such as sentence completion and coreference resolution) but also tasks beyond ‚Äútraditional‚Äù NLP tasks (such as describing Python codes and solving logic grid puzzles) without being explicitly trained on them.

In the rest of this blog post, we showcase two applications with T0++ (a variant of T0 trained with more NLP tasks): producing various cooking recommendations and answering questions about world knowledge.

### Chef T0
T0++ can provide cooking instructions even though it is not trained on cooking recipes data (Bie≈Ñ et al., 2020). It can even generate high-level instructions for complex recipes.

<img src="uploads/images/example_prompt.png" alt="placeholder" width="400"/> 

What if you have a dish in mind, but you don‚Äôt know its ingredients? Don‚Äôt worry, T0++ got your back!

<img src="uploads/images/example_prompt.png" alt="placeholder" width="400"/> 

And the reverse works just as well.

<img src="uploads/images/example_prompt.png" alt="placeholder" width="400"/> 

What about recommendations for national, regional and seasonal dishes? To T0++, they are all a piece of cake.

<img src="uploads/images/example_prompt.png" alt="placeholder" width="400"/> 

T0++ is also helpful for eggs-ploration of similar dishes.

<img src="uploads/images/example_prompt.png" alt="placeholder" width="400"/> 


### The World According To T0
T0++ is also capable of responding to world knowledge such as human aging, religion, machine learning, and ethics. All the prompts in this section are adapted from Hendrycks et al.‚Äôs (2021)<sup>4</sup> dataset, which aims to measure knowledge acquired by a language model during pretraining. Note that we are not presenting a robust evaluation of T0++ here. We specifically chose questions without technical jargon to make this blog post more accessible to everyone.

Even though T0++ is non-living, does it understand human aging from both biological and social perspectives? Let‚Äôs find out!

<img src="uploads/images/example_prompt.png" alt="placeholder" width="400"/> 

How about some questions about religion?

<img src="uploads/images/example_prompt.png" alt="placeholder" width="400"/> 

One cannot help but wonder if T0++ is knowledgeable about its friends. How much does T0++ know about machine learning?

<img src="uploads/images/example_prompt.png" alt="placeholder" width="400"/> 

We also wonder how T0++ stands up to moral scenarios.

<img src="uploads/images/example_prompt.png" alt="placeholder" width="400"/> 

While we do not intend to let T0++ run a business, let us still subject it to questions about business ethics.

<img src="uploads/images/example_prompt.png" alt="placeholder" width="400"/>

### **Public Accessibility**
You can try T0 directly in your browser üëÜ or [download it from the HuggingFace model repository](https://huggingface.co/bigscience/T0pp). A [smaller version]((https://huggingface.co/bigscience/T0_3B) (3 billion parameters instead of 11 billion parameters) is also available.

Finally, in this Github repository, we showcase scripts to perform inference on T0 with one or multiple GPUs, along with instructions to reproduce training or evaluation reported in our paper (Sanh et al., 2021).

### **Conclusion**
The ability to generalize to new tasks is the cornerstone of a general AI model. We are excited about T0 because we show that it is possible to train a smaller large language model with comparable generalization performance to models with 100s of billions of parameters. We showcase how we can apply T0 to cooking and answering world knowledge, and we are excited to see more of its novel applications and further research on zero-shot learning.

### **Acknowledgments**
We would like to acknowledge the co-authors for this blog post: Yong Zheng-Xin, Victor Sanh, and Steven Liu. 

Thanks to those who provided ideas for applications of T0: Colin Raffel, Victor Sanh, Lintang Sutawika, Zaid Alyafeai, M Saiful Bari, Yong Zheng-Xin, and Albert Webson.

Thanks to those who contributed prompts and figures: Eliza Szczechla, Stella Biderman, and Colin Raffel.

Thanks to the prompt-engineering subgroup at BigScience for creating T0 and providing feedback on the blog post. 


### **References**
[1] Micha≈Ç Bie≈Ñ, Micha≈Ç Gilski, Martyna Maciejewska, Wojciech Taisner, Dawid Wisniewski, and Agnieszka Lawrynowicz. ‚ÄúRecipeNLG: A cooking recipes dataset for semi-structured text generation.‚Äù In *Proceedings of the 13th International Conference on Natural Language Generation*, 2020.

[2] BIG-bench collaboration. ‚ÄúBeyond the imitation game: Measuring and extrapolating the capabilities of language models.‚Äù In preparation, 2021.

[3] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. ‚ÄúLanguage Models are Few-Shot Learners.‚Äù In *Advances in Neural Information Processing Systems*, 2020.

[4] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. ‚ÄúMeasuring Massive Multitask Language Understanding.‚Äù In *Proceedings of the International Conference on Learning Representations (ICLR)*, 2021.

[5] Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander M. Rush. ‚ÄúMultitask Prompted Training Enables Zero-Shot Task Generalization.‚Äù *Preprint (arXiv:2110.08207)*, 2021.

[6] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. ‚ÄúExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer‚Äù. In *Journal of Machine Learning Research*, 2020.

### Attempt on iFrame
<div><a class="text-xs block mb-3 text-gray-300" href="/sentence-transformers/distilbert-base-nli-max-tokens"><code>sentence-transformers/distilbert-base-nli-max-tokens</code></a> <div class="p-5 shadow-sm rounded-xl bg-white max-w-md"><div class="SVELTE_HYDRATER " data-props="{&quot;apiUrl&quot;:&quot;https://api-inference.huggingface.co&quot;,&quot;model&quot;:{&quot;author&quot;:&quot;sentence-transformers&quot;,&quot;autoArchitecture&quot;:&quot;AutoModel&quot;,&quot;branch&quot;:&quot;main&quot;,&quot;cardData&quot;:{&quot;pipeline_tag&quot;:&quot;feature-extraction&quot;,&quot;tags&quot;:[&quot;sentence-transformers&quot;,&quot;feature-extraction&quot;,&quot;sentence-similarity&quot;,&quot;transformers&quot;]},&quot;cardSource&quot;:true,&quot;config&quot;:{&quot;architectures&quot;:[&quot;DistilBertModel&quot;],&quot;model_type&quot;:&quot;distilbert&quot;},&quot;id&quot;:&quot;sentence-transformers/distilbert-base-nli-max-tokens&quot;,&quot;pipeline_tag&quot;:&quot;feature-extraction&quot;,&quot;library_name&quot;:&quot;sentence-transformers&quot;,&quot;mask_token&quot;:&quot;[MASK]&quot;,&quot;modelId&quot;:&quot;sentence-transformers/distilbert-base-nli-max-tokens&quot;,&quot;private&quot;:false,&quot;siblings&quot;:[{&quot;rfilename&quot;:&quot;.gitattributes&quot;},{&quot;rfilename&quot;:&quot;README.md&quot;},{&quot;rfilename&quot;:&quot;config.json&quot;},{&quot;rfilename&quot;:&quot;config_sentence_transformers.json&quot;},{&quot;rfilename&quot;:&quot;modules.json&quot;},{&quot;rfilename&quot;:&quot;pytorch_model.bin&quot;},{&quot;rfilename&quot;:&quot;sentence_bert_config.json&quot;},{&quot;rfilename&quot;:&quot;special_tokens_map.json&quot;},{&quot;rfilename&quot;:&quot;tokenizer.json&quot;},{&quot;rfilename&quot;:&quot;tokenizer_config.json&quot;},{&quot;rfilename&quot;:&quot;vocab.txt&quot;},{&quot;rfilename&quot;:&quot;1_Pooling/config.json&quot;}],&quot;tags&quot;:[&quot;pytorch&quot;,&quot;distilbert&quot;,&quot;arxiv:1908.10084&quot;,&quot;sentence-transformers&quot;,&quot;feature-extraction&quot;,&quot;sentence-similarity&quot;,&quot;transformers&quot;,&quot;pipeline_tag:feature-extraction&quot;],&quot;tag_objs&quot;:[{&quot;id&quot;:&quot;feature-extraction&quot;,&quot;label&quot;:&quot;Feature Extraction&quot;,&quot;type&quot;:&quot;pipeline_tag&quot;},{&quot;id&quot;:&quot;pytorch&quot;,&quot;label&quot;:&quot;PyTorch&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;id&quot;:&quot;sentence-transformers&quot;,&quot;label&quot;:&quot;Sentence Transformers&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;id&quot;:&quot;transformers&quot;,&quot;label&quot;:&quot;Transformers&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;id&quot;:&quot;arxiv:1908.10084&quot;,&quot;label&quot;:&quot;arxiv:1908.10084&quot;,&quot;type&quot;:&quot;arxiv&quot;},{&quot;id&quot;:&quot;distilbert&quot;,&quot;label&quot;:&quot;distilbert&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;id&quot;:&quot;sentence-similarity&quot;,&quot;label&quot;:&quot;sentence-similarity&quot;,&quot;type&quot;:&quot;other&quot;},{&quot;id&quot;:&quot;pipeline_tag:feature-extraction&quot;,&quot;label&quot;:&quot;pipeline_tag:feature-extraction&quot;,&quot;type&quot;:&quot;other&quot;}]},&quot;shouldUpdateUrl&quot;:true}" data-target="InferenceWidget"><div class="flex flex-col w-full max-w-full"> <div class="font-semibold flex items-center mb-2"><div class="text-lg flex items-center"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" class="-ml-1 mr-1 text-yellow-500" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path d="M11 15H6l7-14v8h5l-7 14v-8z" fill="currentColor"></path></svg>
			Hosted inference API</div> <a target="_blank" href="/docs"><svg class="ml-1.5 text-sm text-gray-400 hover:text-black" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M17 22v-8h-4v2h2v6h-3v2h8v-2h-3z" fill="currentColor"></path><path d="M16 8a1.5 1.5 0 1 0 1.5 1.5A1.5 1.5 0 0 0 16 8z" fill="currentColor"></path><path d="M16 30a14 14 0 1 1 14-14a14 14 0 0 1-14 14zm0-26a12 12 0 1 0 12 12A12 12 0 0 0 16 4z" fill="currentColor"></path></svg></a></div> <div class="flex items-center text-sm text-gray-500 mb-1.5"><div class="inline-flex items-center"><svg class="mr-1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M27 3H5a2 2 0 0 0-2 2v22a2 2 0 0 0 2 2h22a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2zm0 2v4H5V5zm-10 6h10v7H17zm-2 7H5v-7h10zM5 20h10v7H5zm12 7v-7h10v7z"></path></svg> <span>Feature Extraction</span></div> <div class="ml-auto"></div></div> <form><div class="flex h-10"><input class="form-input-alt flex-1 rounded-r-none " placeholder="Your sentence here..." required="" type="text"> <button class="btn-widget w-24 h-10 px-5 rounded-l-none border-l-0 " type="submit">Compute</button></div></form> <div class="mt-1.5"><div class="text-gray-400 text-xs">This model is currently loaded and running on the Inference API.</div> </div>   <div class="mt-auto pt-4 flex items-center text-xs text-gray-500"><button class="flex items-center cursor-not-allowed text-gray-300" disabled=""><svg class="mr-1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32" style="transform: rotate(360deg);"><path d="M31 16l-7 7l-1.41-1.41L28.17 16l-5.58-5.59L24 9l7 7z" fill="currentColor"></path><path d="M1 16l7-7l1.41 1.41L3.83 16l5.58 5.59L8 23l-7-7z" fill="currentColor"></path><path d="M12.419 25.484L17.639 6l1.932.518L14.35 26z" fill="currentColor"></path></svg>
		JSON Output</button> <button class="flex items-center ml-auto"><svg class="mr-1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M22 16h2V8h-8v2h6v6z" fill="currentColor"></path><path d="M8 24h8v-2h-6v-6H8v8z" fill="currentColor"></path><path d="M26 28H6a2.002 2.002 0 0 1-2-2V6a2.002 2.002 0 0 1 2-2h20a2.002 2.002 0 0 1 2 2v20a2.002 2.002 0 0 1-2 2zM6 6v20h20.001L26 6z" fill="currentColor"></path></svg>
		Maximize</button></div> </div></div></div>

